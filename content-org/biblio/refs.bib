@book{boydIntroductionAppliedLinear2018,
  title           = {Introduction to {{Applied Linear Algebra}}: {{Vectors}},
                  {{Matrices}}, and {{Least Squares}}},
  shorttitle      = {Introduction to {{Applied Linear Algebra}}},
  author          = {Boyd, Stephen and Vandenberghe, Lieven},
  date            = {2018-06-07},
  edition         = 1,
  publisher       = {{Cambridge University Press}},
  doi             = {10.1017/9781108583664},
  url             =
                  {https://www.cambridge.org/core/product/identifier/9781108583664/type/book},
  urldate         = {2020-02-29},
  file            = {/run/media/haozeke/Storage/Zotero/storage/9FTQK2DN/Boyd and
                  Vandenberghe - 2018 - Introduction to Applied Linear Algebra
                  Vectors, M.pdf},
  isbn            = {978-1-108-58366-4},
  langid          = {english}
}

@article{breimanBaggingPredictors1996,
  title           = {Bagging {{Predictors}}},
  author          = {Breiman, Leo},
  date            = {1996-08-01},
  journaltitle    = {Machine Learning},
  shortjournal    = {Machine Learning},
  volume          = 24,
  pages           = {123--140},
  issn            = {1573-0565},
  doi             = {10.1023/A:1018054314350},
  url             = {https://doi.org/10.1023/A:1018054314350},
  urldate         = {2020-03-24},
  abstract        = {Bagging predictors is a method for generating multiple
                  versions of a predictor and using these to get an aggregated
                  predictor. The aggregation averages over the versions when
                  predicting a numerical outcome and does a plurality vote when
                  predicting a class. The multiple versions are formed by making
                  bootstrap replicates of the learning set and using these as
                  new learning sets. Tests on real and simulated data sets using
                  classification and regression trees and subset selection in
                  linear regression show that bagging can give substantial gains
                  in accuracy. The vital element is the instability of the
                  prediction method. If perturbing the learning set can cause
                  significant changes in the predictor constructed, then bagging
                  can improve accuracy.},
  file            =
                  {/run/media/haozeke/Storage/Zotero/storage/4ETSRHWZ/breiman1996.pdf;/run/media/haozeke/Storage/Zotero/storage/R9XRH2MW/Breiman
                  - 1996 - Bagging Predictors.pdf},
  langid          = {english},
  number          = 2
}

@book{cichoszDataMiningAlgorithms2015,
  title           = {Data Mining Algorithms: Explained Using {{R}}},
  shorttitle      = {Data Mining Algorithms},
  author          = {Cichosz, Pawel},
  date            = 2015,
  publisher       = {{John Wiley \& Sons Inc}},
  location        = {{Chichester, West Sussex ; Malden, MA}},
  abstract        = {"This book narrows down the scope of data mining by
                  adopting a heavily modeling-oriented perspective"--},
  file            = {/run/media/haozeke/Storage/Zotero/storage/F8LJTR7K/Cichosz
                  - Data Mining Algorithms.pdf},
  isbn            = {978-1-118-95084-5},
  keywords        = {Computer algorithms,Data mining,MATHEMATICS / Probability &
                  Statistics / General,R (Computer program language)},
  pagetotal       = 1
}

@software{cutlerRandomForestBreimanCutler2018,
  title = {{{randomForest}}: {{Breiman}} and {{Cutler}}'s {{Random Forests}} for {{Classification}} and {{Regression}}},
  shorttitle = {{{randomForest}}},
  author = {Cutler, Fortran original by Leo Breiman {and} Adele and Wiener, R. port by Andy Liaw {and} Matthew},
  date = {2018-03-25},
  url = {https://CRAN.R-project.org/package=randomForest},
  urldate = {2020-03-24},
  abstract = {Classification and regression based on a forest of trees using random inputs, based on Breiman (2001) {$<$}doi:10.1023/A:1010933404324{$>$}.},
  keywords = {Environmetrics,MachineLearning,MissingData},
  version = {4.6-14}
}

@book{efronJackknifeBootstrapOther1982,
  title           = {The Jackknife, the Bootstrap, and Other Resampling Plans},
  author          = {Efron, Bradley},
  date            = 1982,
  publisher       = {{Society for Industrial and Applied Mathematics}},
  location        = {{Philadelphia, Pa}},
  file            = {/run/media/haozeke/Storage/Zotero/storage/H9HZWKMN/BIO
                  63.pdf;/run/media/haozeke/Storage/Zotero/storage/KVPTKFL3/(CBMS
                  38) Bradley Efron - The Jackknife, the Bootstrap, and Other
                  Resampling Plans (CBMS-NSF Regional Conference Series in
                  Applied Mathematics)-Society for Industrial Mathematics
                  (1987).djvu},
  isbn            = {978-0-89871-179-0},
  keywords        = {Bootstrap (Statistics),Error analysis
                  (Mathematics),Estimation theory,Jackknife
                  (Statistics),Resampling (Statistics)},
  number          = 38,
  pagetotal       = 92,
  series          = {{{CBMS}}-{{NSF Regional}} Conference Series in Applied
                  Mathematics}
}

@software{galiliDendextendExtendingDendrogram2020,
  title = {Dendextend: {{Extending}} 'dendrogram' {{Functionality}} in {{R}}},
  shorttitle = {Dendextend},
  author = {Galili, Tal and Benjamini, Yoav and Simpson, Gavin, and Gregory, Jefferis and Marco, Gallotta and Renaudie, Johan and Hornik, Kurt and Ligges, Uwe and Spiess, Andrej-Nikolai and Horvath, Steve and Langfelder, Peter, Mark Van Der Loo and Andrie de Vries,and Zuguang Gu and Ma, John and G, Krzysiek and Hummel, Manuela and Clark, Chase and Graybuck, Lucas and jdetribol and Ho, Ben and Perreault, Samuel and Hennig, Christian and Bradley, David},
  date = {2020-02-28},
  url = {https://CRAN.R-project.org/package=dendextend},
  urldate = {2020-03-23},
  abstract = {Offers a set of functions for extending 'dendrogram' objects in R, letting you visualize and compare trees of 'hierarchical clusterings'. You can (1) Adjust a tree's graphical parameters - the color, size, type, etc of its branches, nodes and labels. (2) Visually and statistically compare different 'dendrograms' to one another.},
  keywords = {Cluster,Phylogenetics},
  options = {useprefix=true},
  version = {1.13.4}
}

@book{hastieElementsStatisticalLearning2009,
  title           = {The Elements of Statistical Learning: Data Mining,
                  Inference, and Prediction},
  shorttitle      = {The Elements of Statistical Learning},
  author          = {Hastie, Trevor and Tibshirani, Robert and Friedman, J. H.},
  date            = 2009,
  edition         = {2nd ed},
  publisher       = {{Springer}},
  location        = {{New York, NY}},
  file            = {/run/media/haozeke/Storage/Zotero/storage/2MQRYYQM/Hastie
                  et al. - 2009 - The elements of statistical learning data
                  mining,.pdf},
  isbn            = {978-0-387-84857-0},
  keywords        = {Bioinformatics,Computational intelligence,Data
                  mining,Forecasting,Inference,Machine
                  learning,Methodology,Statistics},
  note            = 00359,
  pagetotal       = 745,
  series          = {Springer Series in Statistics}
}

@book{jamesIntroductionStatisticalLearning2013,
  title           = {An {{Introduction}} to {{Statistical Learning}}},
  author          = {James, Gareth and Witten, Daniela and Hastie, Trevor and
                  Tibshirani, Robert},
  date            = 2013,
  volume          = 103,
  publisher       = {{Springer New York}},
  location        = {{New York, NY}},
  doi             = {10.1007/978-1-4614-7138-7},
  url             = {http://link.springer.com/10.1007/978-1-4614-7138-7},
  urldate         = {2020-03-19},
  file            = {/run/media/haozeke/Storage/Zotero/storage/7MPLYQCK/James et
                  al. - 2013 - An Introduction to Statistical Learning.pdf},
  isbn            = {978-1-4614-7138-7},
  langid          = {english},
  series          = {Springer {{Texts}} in {{Statistics}}}
}

@article{kassambaraPracticalGuideCluster,
  title           = {Practical {{Guide To Cluster Analysis}} in {{R}}},
  author          = {Kassambara, Alboukadel},
  pages           = 187,
  file            =
                  {/run/media/haozeke/Storage/Zotero/storage/MGHDC7NF/Kassambara
                  - Copyright Â©2017 by Alboukadel Kassambara. All righ.pdf},
  langid          = {english}
}

@software{kuhnCaretClassificationRegression2020,
  title = {Caret: {{Classification}} and {{Regression Training}}},
  shorttitle = {Caret},
  author = {Kuhn, Max and Wing, Jed and Weston, Steve and Williams, Andre and Keefer, Chris and Engelhardt, Allan and Cooper, Tony and Mayer, Zachary and Kenkel, Brenton and R Core Team and Benesty, Michael and Lescarbeau, Reynald and Ziem, Andrew and Scrucca, Luca and Tang, Yuan and Candan, Can and Hunt, Tyler},
  date = {2020-03-20},
  url = {https://CRAN.R-project.org/package=caret},
  urldate = {2020-03-24},
  abstract = {Misc functions for training and plotting classification and regression models.},
  keywords = {HighPerformanceComputing,MachineLearning,Multivariate},
  version = {6.0-86}
}

@software{langMlr3MachineLearning2020,
  title = {Mlr3: {{Machine Learning}} in {{R}} - {{Next Generation}}},
  shorttitle = {Mlr3},
  author = {Lang, Michel and Bischl, Bernd and Richter, Jakob and Schratz, Patrick and Casalicchio, Giuseppe and Coors, Stefan and Au, Quay and Binder, Martin},
  date = {2020-03-09},
  url = {https://CRAN.R-project.org/package=mlr3},
  urldate = {2020-03-24},
  abstract = {Efficient, object-oriented programming on the building blocks of machine learning. Provides 'R6' objects for tasks, learners, resamplings, and measures. The package is geared towards scalability and larger datasets by supporting parallelization and out-of-memory data-backends like databases. While 'mlr3' focuses on the core computational operations, add-on packages provide additional functionality.},
  keywords = {MachineLearning},
  version = {0.1.8}
}

@software{langRCurlGeneralNetwork2020,
  title = {{{RCurl}}: {{General Network}} ({{HTTP}}/{{FTP}}/...) {{Client Interface}} for {{R}}},
  shorttitle = {{{RCurl}}},
  author = {Lang, Duncan Temple},
  date = {2020-01-19},
  url = {https://CRAN.R-project.org/package=RCurl},
  urldate = {2020-03-21},
  abstract = {A wrapper for 'libcurl' {$<$}http://curl.haxx.se/libcurl/{$>$} Provides functions to allow one to compose general HTTP requests and provides convenient functions to fetch URIs, get \& post forms, etc. and process the results returned by the Web server. This provides a great deal of control over the HTTP/FTP/... connection and the form of the request while providing a higher-level interface than is available just using R socket connections. Additionally, the underlying implementation is robust and extensive, supporting FTP/FTPS/TFTP (uploads and downloads), SSL/HTTPS, telnet, dict, ldap, and also supports cookies, redirects, authentication, etc.},
  keywords = {WebTechnologies},
  version = {1.98-1.1}
}

@article{mcquittySimilarityAnalysisReciprocal2016,
  title           = {Similarity {{Analysis}} by {{Reciprocal Pairs}} for
                  {{Discrete}} and {{Continuous Data}}:},
  shorttitle      = {Similarity {{Analysis}} by {{Reciprocal Pairs}} for
                  {{Discrete}} and {{Continuous Data}}},
  author          = {McQuitty, Louis L.},
  date            = {2016-07-02},
  journaltitle    = {Educational and Psychological Measurement},
  publisher       = {{Sage PublicationsSage CA: Thousand Oaks, CA}},
  doi             = {10.1177/001316446602600402},
  url             =
                  {https://journals.sagepub.com/doi/10.1177/001316446602600402},
  urldate         = {2020-03-23},
  file            =
                  {/run/media/haozeke/Storage/Zotero/storage/P3ZBTP3Y/mcquitty1966.pdf;/run/media/haozeke/Storage/Zotero/storage/ZACSIFKN/mcquitty1966.pdf;/run/media/haozeke/Storage/Zotero/storage/FRN38ZQW/001316446602600402.html},
  langid          = {english}
}

@software{milborrowRpartPlotPlot2019,
  title = {Rpart.Plot: {{Plot}} 'rpart' {{Models}}: {{An Enhanced Version}} of 'Plot.Rpart'},
  shorttitle = {Rpart.Plot},
  author = {Milborrow, Stephen},
  date = {2019-08-22},
  url = {https://CRAN.R-project.org/package=rpart.plot},
  urldate = {2020-03-24},
  abstract = {Plot 'rpart' models. Extends plot.rpart() and text.rpart() in the 'rpart' package.},
  version = {3.0.8}
}

@article{murtaghWardHierarchicalAgglomerative2014,
  title           = {Wardâs {{Hierarchical Agglomerative Clustering Method}}:
                  {{Which Algorithms Implement Ward}}âs {{Criterion}}?},
  shorttitle      = {Wardâs {{Hierarchical Agglomerative Clustering Method}}},
  author          = {Murtagh, Fionn and Legendre, Pierre},
  date            = {2014-10-01},
  journaltitle    = {Journal of Classification},
  shortjournal    = {J Classif},
  volume          = 31,
  pages           = {274--295},
  issn            = {1432-1343},
  doi             = {10.1007/s00357-014-9161-z},
  url             = {https://doi.org/10.1007/s00357-014-9161-z},
  urldate         = {2020-03-23},
  abstract        = {The Ward error sum of squares hierarchical clustering
                  method has been very widely used since its first description
                  by Ward in a 1963 publication. It has also been generalized in
                  various ways. Two algorithms are found in the literature and
                  software, both announcing that they implement the Ward
                  clustering method. When applied to the same distance matrix,
                  they produce different results. One algorithm preserves Wardâs
                  criterion, the other does not. Our survey work and case
                  studies will be useful for all those involved in developing
                  software for data analysis using Wardâs hierarchical
                  clustering method.},
  file            = {/run/media/haozeke/Storage/Zotero/storage/CQF57BXP/Murtagh
                  and Legendre - 2014 - Wardâs Hierarchical Agglomerative
                  Clustering
                  Metho.pdf;/run/media/haozeke/Storage/Zotero/storage/VCGRBQNI/murtagh2014.pdf},
  langid          = {english},
  number          = 3
}

@software{therneauRpartRecursivePartitioning2019,
  title = {Rpart: {{Recursive Partitioning}} and {{Regression Trees}}},
  shorttitle = {Rpart},
  author = {Therneau, Terry and Atkinson, Beth and {port}, Brian Ripley (producer of the initial R. and maintainer 1999-2017)},
  date = {2019-04-12},
  url = {https://CRAN.R-project.org/package=rpart},
  urldate = {2020-03-24},
  abstract = {Recursive partitioning for classification, regression and survival trees. An implementation of most of the functionality of the 1984 book by Breiman, Friedman, Olshen and Stone.},
  keywords = {Environmetrics,MachineLearning,Multivariate,Survival},
  options = {useprefix=true},
  version = {4.1-15}
}

@article{tibshiraniEstimatingNumberClusters2001,
  title           = {Estimating the Number of Clusters in a Data Set via the Gap
                  Statistic},
  author          = {Tibshirani, Robert and Walther, Guenther and Hastie,
                  Trevor},
  date            = {2001-05},
  journaltitle    = {Journal of the Royal Statistical Society: Series B
                  (Statistical Methodology)},
  shortjournal    = {J Royal Statistical Soc B},
  volume          = 63,
  pages           = {411--423},
  issn            = {1369-7412, 1467-9868},
  doi             = {10.1111/1467-9868.00293},
  url             = {http://doi.wiley.com/10.1111/1467-9868.00293},
  urldate         = {2020-03-23},
  file            =
                  {/run/media/haozeke/Storage/Zotero/storage/E674HD8Q/tibshirani2001.pdf},
  langid          = {english},
  number          = 2
}

@software{wickhamDplyrGrammarData2020,
  title = {Dplyr: {{A Grammar}} of {{Data Manipulation}}},
  shorttitle = {Dplyr},
  author = {Wickham, Hadley and FranÃ§ois, Romain and Henry, Lionel and MÃ¼ller, Kirill and RStudio},
  date = {2020-03-07},
  url = {https://CRAN.R-project.org/package=dplyr},
  urldate = {2020-03-24},
  abstract = {A fast, consistent tool for working with data frame like objects, both in memory and out of memory.},
  keywords = {ModelDeployment},
  version = {0.8.5}
}

@software{wrightRangerFastImplementation2020,
  title = {Ranger: {{A Fast Implementation}} of {{Random Forests}}},
  shorttitle = {Ranger},
  author = {Wright, Marvin N. and Wager, Stefan and Probst, Philipp},
  date = {2020-01-10},
  url = {https://CRAN.R-project.org/package=ranger},
  urldate = {2020-03-24},
  abstract = {A fast implementation of Random Forests, particularly suited for high dimensional data. Ensembles of classification, regression, survival and probability prediction trees are supported. Data from genome-wide association studies can be analyzed efficiently. In addition to data frames, datasets of class 'gwaa.data' (R package 'GenABEL') and 'dgCMatrix' (R package 'Matrix') can be directly analyzed.},
  keywords = {MachineLearning,Survival},
  version = {0.12.1}
}

@book{zhouEnsembleMethodsFoundations2012,
  title           = {Ensemble {{Methods}}: {{Foundations}} and {{Algorithms}}},
  shorttitle      = {Ensemble {{Methods}}},
  author          = {Zhou, Zhi-Hua},
  date            = {2012-06-06},
  edition         = 0,
  publisher       = {{Chapman and Hall/CRC}},
  doi             = {10.1201/b12207},
  url             = {https://www.taylorfrancis.com/books/9781439830055},
  urldate         = {2020-03-24},
  file            = {/run/media/haozeke/Storage/Zotero/storage/TAV8WV8D/Zhou -
                  2012 - Ensemble Methods Foundations and Algorithms.pdf},
  isbn            = {978-0-429-15109-5},
  langid          = {english}
}

@preamble{ "\ifdefined\DeclarePrefChars\DeclarePrefChars{'â-}\else\fi " }
